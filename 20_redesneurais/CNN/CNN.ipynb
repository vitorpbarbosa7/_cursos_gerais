{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Este c처digo classifica imagens </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Load the data to classify\n",
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 223s 1us/step\n"
     ]
    }
   ],
   "source": [
    "#Divis찾o da base:\n",
    "(x_train,y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#Podemos ver que todos s찾o numpy arrays\n",
    "print(type(x_train))\n",
    "print(type(y_train))\n",
    "print(type(x_test))\n",
    "print(type(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> S찾o 50000 imagens, com 32x32 pixels com profundidade de 3 (RGB) </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "y_train shape: (50000, 1)\n",
      "x_test shape: (10000, 32, 32, 3)\n",
      "y_test shape: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "#Continuing to explore the data:\n",
    "#Get the shapes:\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To see the first image (at index=0) in the training data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 59,  62,  63],\n",
       "        [ 43,  46,  45],\n",
       "        [ 50,  48,  43],\n",
       "        ...,\n",
       "        [158, 132, 108],\n",
       "        [152, 125, 102],\n",
       "        [148, 124, 103]],\n",
       "\n",
       "       [[ 16,  20,  20],\n",
       "        [  0,   0,   0],\n",
       "        [ 18,   8,   0],\n",
       "        ...,\n",
       "        [123,  88,  55],\n",
       "        [119,  83,  50],\n",
       "        [122,  87,  57]],\n",
       "\n",
       "       [[ 25,  24,  21],\n",
       "        [ 16,   7,   0],\n",
       "        [ 49,  27,   8],\n",
       "        ...,\n",
       "        [118,  84,  50],\n",
       "        [120,  84,  50],\n",
       "        [109,  73,  42]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[208, 170,  96],\n",
       "        [201, 153,  34],\n",
       "        [198, 161,  26],\n",
       "        ...,\n",
       "        [160, 133,  70],\n",
       "        [ 56,  31,   7],\n",
       "        [ 53,  34,  20]],\n",
       "\n",
       "       [[180, 139,  96],\n",
       "        [173, 123,  42],\n",
       "        [186, 144,  30],\n",
       "        ...,\n",
       "        [184, 148,  94],\n",
       "        [ 97,  62,  34],\n",
       "        [ 83,  53,  34]],\n",
       "\n",
       "       [[177, 144, 116],\n",
       "        [168, 129,  94],\n",
       "        [179, 142,  87],\n",
       "        ...,\n",
       "        [216, 184, 140],\n",
       "        [151, 118,  84],\n",
       "        [123,  92,  72]]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Show the image as a picture, not a sequence of arrays in RGB:\n",
    "import matplotlib.pyplot as plt\n",
    "img = plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label is: [6]\n"
     ]
    }
   ],
   "source": [
    "#Print the label of the image\n",
    "print('The label is:', y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> One Hot Encoder </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#Creating the y data set:\n",
    "#One-Hot Encoding: Conver the labels into a set of 10 numbers to input into the neural network:\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_one_hot = to_categorical(y_test)\n",
    "\n",
    "#Print the labels for the training dataset:\n",
    "print(y_train_one_hot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The one hot label is: [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#Print an example of the new labels:\n",
    "print('The one hot label is:', y_train_one_hot[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> N첬mero de GPUs dispon챠veis </h4>\n",
    "(Quando rodo no Linux d찼 0 porque o CUDA n찾o est찼 instalado, mas no Windows d찼 1, porque CUDA e cuDNN est찾o devidamente instalados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Normaliza챌찾o nos previsores</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize the pixels in the images to be values between 0 and 1\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Constru챌찾o da CNN </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arquitetura\n",
    "from keras.models import Sequential \n",
    "#Tipo de camada:\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "#Create the architecture\n",
    "model = Sequential()\n",
    "\n",
    "#Convolution layer\n",
    "#5x5 dimens찾o do filtro\n",
    "#A dimens찾o s처 챕 necess찼ria ser informada na primeira camada que recebe a iamgem\n",
    "#Aplicarei 32 filtros \n",
    "# N첬mero de linhas no kernel de convolu챌찾o : 5\n",
    "# N첬mero de colunas do kernel de convolu챌찾o : 5\n",
    "#Dimens찾o da entrada: 32x32 imagem RGB. Espacialmente 챕 tridimensional\n",
    "# Fun챌찾o de ativa챌찾o utilizada : Unidade linear retificada (ReLu)\n",
    "model.add(Conv2D(32, (5,5), activation = 'relu', input_shape=(32,32,3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MaxPooling layer\n",
    "#Se a imagem era originalmente de 32x32 ela ser찼 reduzida para 16x16\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "#Pr처xima camada de convolu챌찾o :\n",
    "model.add(Conv2D(32, (5,5), activation = 'relu'))\n",
    "\n",
    "#Pr처xima camada de MaxPooling:\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "#Flatten Layer:\n",
    "model.add(Flatten())\n",
    "\n",
    "#Create the neural network\n",
    "model.add(Dense(1000,activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#Last layer which is responsible to return probabilies:\n",
    "\n",
    "output_dimension= np.array(y_train_one_hot[0].shape)\n",
    "model.add(Dense(output_dimension[0], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model:\n",
    "#Categorical cross entropy is used when the output class is greater than two, \n",
    "#and it is our case here, where we have 10 different classes\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer = 'adam',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>  Treinar o modelo </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35000 samples, validate on 15000 samples\n",
      "Epoch 1/10\n",
      "35000/35000 [==============================] - 10s 293us/step - loss: 1.6968 - accuracy: 0.3868 - val_loss: 1.4838 - val_accuracy: 0.4689\n",
      "Epoch 2/10\n",
      "35000/35000 [==============================] - 7s 202us/step - loss: 1.3421 - accuracy: 0.5206 - val_loss: 1.3021 - val_accuracy: 0.5377\n",
      "Epoch 3/10\n",
      "35000/35000 [==============================] - 7s 202us/step - loss: 1.1962 - accuracy: 0.5780 - val_loss: 1.2228 - val_accuracy: 0.5674\n",
      "Epoch 4/10\n",
      "35000/35000 [==============================] - 7s 200us/step - loss: 1.0914 - accuracy: 0.6157 - val_loss: 1.1499 - val_accuracy: 0.5968\n",
      "Epoch 5/10\n",
      "35000/35000 [==============================] - 8s 217us/step - loss: 1.0064 - accuracy: 0.6473 - val_loss: 1.0542 - val_accuracy: 0.6336\n",
      "Epoch 6/10\n",
      "35000/35000 [==============================] - 8s 220us/step - loss: 0.9531 - accuracy: 0.6677 - val_loss: 1.0512 - val_accuracy: 0.6383\n",
      "Epoch 7/10\n",
      "35000/35000 [==============================] - 8s 216us/step - loss: 0.8755 - accuracy: 0.6961 - val_loss: 1.0341 - val_accuracy: 0.6423\n",
      "Epoch 8/10\n",
      "35000/35000 [==============================] - 8s 214us/step - loss: 0.8101 - accuracy: 0.7187 - val_loss: 1.0390 - val_accuracy: 0.6447\n",
      "Epoch 9/10\n",
      "35000/35000 [==============================] - 8s 219us/step - loss: 0.7447 - accuracy: 0.7411 - val_loss: 0.9850 - val_accuracy: 0.6605\n",
      "Epoch 10/10\n",
      "35000/35000 [==============================] - 8s 221us/step - loss: 0.6878 - accuracy: 0.7621 - val_loss: 0.9591 - val_accuracy: 0.6737\n"
     ]
    }
   ],
   "source": [
    "#Train (fit) the model\n",
    "hist = model.fit(x_train, y_train_one_hot,\n",
    "                 batch_size = 256,\n",
    "                 epochs = 10,\n",
    "                 validation_split = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
